{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "Stopwords = set(stopwords.words('english'))\n",
    "import pickle\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "import re\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = set(stopwords.words('english'))\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q01\n",
      "Q02\n",
      "Q03\n",
      "Q04\n",
      "Q05\n",
      "Q06\n",
      "Q07\n",
      " Q08\n",
      " Q09\n",
      "Q10\n",
      "Q11\n",
      "Q12\n",
      "Q13\n",
      "Q14\n",
      "Q15\n",
      "Q16\n",
      "Q17\n",
      "Q18\n",
      "Q19\n",
      "Q20\n"
     ]
    }
   ],
   "source": [
    "with open('queries.txt','r') as file:\n",
    "    q_file = file.read()\n",
    "    file.close()\n",
    "    \n",
    "q_dict = {}\n",
    "for l in q_file.split('\\n'):\n",
    "    if(len(l.split('\\t'))==2):\n",
    "        \n",
    "        q_id,query = l.split('\\t')\n",
    "        \n",
    "        q_dict[q_id] = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q01': 'Code for parsing and generating JSON data',\n",
       " 'Q02': 'statistical computing and graphics ',\n",
       " 'Q03': 'programming language  in data mining',\n",
       " 'Q04': 'Microsoft Corporation  Analytics',\n",
       " 'Q05': ' Facebook  Integrity  engagement team ',\n",
       " 'Q06': 'stillbirth is  birth of child',\n",
       " 'Q07': 'abnormal testicular development',\n",
       " ' Q08': 'course of testosterone prescribed',\n",
       " ' Q09': 'colourful Matrushka',\n",
       " 'Q10': 'Spanning the literary globe',\n",
       " 'Q11': 'chemical biology, molecular genetics, and immunochemistry',\n",
       " 'Q12': 'Sundarbans National Park',\n",
       " 'Q13': 'what is State Transport Corporation',\n",
       " 'Q14': 'Shatrunjaya Palitana Tirtha',\n",
       " 'Q15': 'Explain fibonacci heap',\n",
       " 'Q16': 'Explain monte carlo method',\n",
       " 'Q17': 'what is diagrammatic structure',\n",
       " 'Q18': \"what is Fermat's little theorem\",\n",
       " 'Q19': 'symmetry Arithmetical investigation',\n",
       " 'Q20': 'what is choas theory'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('post_file.pkl', 'rb') as f:\n",
    "    tf = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "with open('file_num.pkl', 'rb') as f:\n",
    "    file_num = pickle.load(f)\n",
    "    f.close()\n",
    "with open('df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    f.close()\n",
    "with open('length.pkl', 'rb') as f:\n",
    "    length = pickle.load(f)\n",
    "    f.close()\n",
    "with open('l2_norm.pkl', 'rb') as f:\n",
    "    l2_norm = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BooleanRetreval(qry): \n",
    "    q_list=[]\n",
    "    regex = re.compile('[^a-zA-Z0-9\\s]')\n",
    "    inputt = re.sub(regex,'',qry)\n",
    "    inputt = re.sub(re.compile('\\d'),'',inputt)\n",
    "    inputt = word_tokenize(inputt)\n",
    "    for i in range(len(inputt)):\n",
    "        inputt[i] = ps.stem(inputt[i])\n",
    "    inputt = [i for i in inputt if i not in Stopwords]\n",
    "\n",
    "    ls=[]\n",
    "    for i in range(8635):\n",
    "        ls.append(0)\n",
    "    for j in tf[inputt[0]].keys():\n",
    "        ls[j] = 1\n",
    "    if(len(inputt) >1):\n",
    "        for i in range(1,len(inputt)):\n",
    "            for j in tf[inputt[i]].keys():\n",
    "                if(ls[j] ==i):\n",
    "                    ls[j] = ls[j] + 1\n",
    "    for i in range(8635):\n",
    "        if(ls[i] == len(inputt)):\n",
    "            q_list.append(file_num[i])\n",
    "    return q_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(qry):\n",
    "    q_list=[]\n",
    "    import math\n",
    "    regex = re.compile('[^a-zA-Z0-9\\s]')\n",
    "    inputt = re.sub(regex,'',qry)\n",
    "    inputt = re.sub(re.compile('\\d'),'',inputt)\n",
    "    inputt = word_tokenize(inputt)\n",
    "    for i in range(len(inputt)):\n",
    "        inputt[i] = ps.stem(inputt[i])\n",
    "    inputt = [i for i in inputt if i not in Stopwords]\n",
    "    lis = []\n",
    "\n",
    "    for j in range(8635):\n",
    "        temp = []\n",
    "        for i in inputt:\n",
    "            try:\n",
    "                tf_idf = tf[i][j]*math.log(8635/df[i])\n",
    "            except KeyError:\n",
    "                tf_idf = 0\n",
    "            tf_idf = tf_idf/l2_norm[j]\n",
    "            temp.append(tf_idf)\n",
    "        lis.append(temp)\n",
    "    norm = 0\n",
    "    temp_tf_idf =[]\n",
    "\n",
    "    for i in inputt:\n",
    "        qtf_idf = inputt.count(i)*math.log(8635/df[i])\n",
    "        norm = norm + qtf_idf**2\n",
    "        norm = math.sqrt(norm)\n",
    "        temp_tf_idf.append(qtf_idf)\n",
    "\n",
    "    for i in range(len(temp_tf_idf)):\n",
    "        temp_tf_idf[i] = temp_tf_idf[i]/norm\n",
    "\n",
    "    top=[]\n",
    "    for i in range(8635):\n",
    "        top.append(np.dot(lis[i],temp_tf_idf))\n",
    "    for i in range(30):\n",
    "        max_value = max(top)\n",
    "        q_list.append(file_num[top.index(max_value)])\n",
    "        top[top.index(max_value)] = 0\n",
    "    return q_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bm 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(qry):\n",
    "    q_list=[]\n",
    "    k=1.2\n",
    "    b = 0.75\n",
    "    summ = 0\n",
    "    for i in range(8635):\n",
    "        summ = summ + length[i]\n",
    "    l_avg = summ/8635\n",
    "    import math\n",
    "    regex = re.compile('[^a-zA-Z0-9\\s]')\n",
    "    inputt = re.sub(regex,'',qry)\n",
    "    inputt = re.sub(re.compile('\\d'),'',inputt)\n",
    "    inputt = word_tokenize(inputt)\n",
    "    for i in range(len(inputt)):\n",
    "        inputt[i] = ps.stem(inputt[i])\n",
    "    inputt = [i for i in inputt if i not in Stopwords]\n",
    "    ls = []\n",
    "    for i in range(8635):\n",
    "        x =0\n",
    "        for j in inputt:\n",
    "            try:\n",
    "                idf = math.log((8635-df[j]+0.5)/(df[j]+0.5))\n",
    "            except KeyError:\n",
    "                idf =0\n",
    "            try:\n",
    "                tff= tf[j][i]\n",
    "            except KeyError:\n",
    "                tff = 0\n",
    "            x = x + idf*(k+1)*tff/(tff+k*(1-b+b*(length[i]/l_avg)))\n",
    "        ls.append(x)\n",
    "        \n",
    "    for i in range(15):\n",
    "        max_value = max(ls)\n",
    "        q_list.append(file_num[ls.index(max_value)])\n",
    "        ls[ls.index(max_value)] = 0\n",
    "    return q_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "smb = 'QueryId,Iteration,DocId,Relevance'\n",
    "tfidf = 'QueryId,Iteration,DocId,Relevance'\n",
    "bmtf = 'QueryId,Iteration,DocId,Relevance'\n",
    "smb = 'QueryId,Iteration,DocId,Relevance'\n",
    "\n",
    "for q_id in q_dict:\n",
    "    qry = q_dict[q_id]\n",
    "    \n",
    "    q_list = BooleanRetreval(qry)\n",
    "    c = 0\n",
    "    for i in q_list:\n",
    "        if c == 10:break\n",
    "        c += 1\n",
    "        smb = smb + str('\\n'+q_id+','+'1,'+i+','+'1')\n",
    "    \n",
    "    k = 0\n",
    "    while (c<10):\n",
    "        if file_num[k] not in q_list:\n",
    "            smb = smb + str('\\n'+q_id+','+'1,'+file_num[k]+','+'0')\n",
    "            c += 1\n",
    "        else:\n",
    "            k += 1\n",
    "    \n",
    "    q_list = tf_idf(qry)\n",
    "    c = 0\n",
    "    for i in q_list:\n",
    "        if c == 10:break\n",
    "        c += 1\n",
    "        tfidf = tfidf + str('\\n'+q_id+','+'1,'+i+','+'1')\n",
    "    \n",
    "    k = 0\n",
    "    while (c<10):\n",
    "        if file_num[k] not in q_list:\n",
    "            tfidf = tfidf + str('\\n'+q_id+','+'1,'+file_num[k]+','+'0')\n",
    "            c += 1\n",
    "        else:\n",
    "            k += 1 \n",
    "    \n",
    "    \n",
    "    q_list = bm25(qry)\n",
    "    c = 0\n",
    "    for i in q_list:\n",
    "        if c == 10:break\n",
    "        c += 1\n",
    "        bmtf = bmtf + str('\\n'+q_id+','+'1,'+i+','+'1')\n",
    "    \n",
    "    k = 0\n",
    "    while (c<10):\n",
    "        if file_num[k] not in q_list:\n",
    "            bmtf = bmtf + str('\\n'+q_id+','+'1,'+file_num[k]+','+'0')\n",
    "            c += 1\n",
    "        else:\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Boolean.csv','w') as file:\n",
    "    file.write(smb)\n",
    "    file.close()\n",
    "with open('Tf-Idf.csv','w') as file:\n",
    "    file.write(tfidf)\n",
    "    file.close()\n",
    "with open('BM25.csv','w') as file:\n",
    "    file.write(bmtf)\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
